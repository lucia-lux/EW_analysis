{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 32-bit"
    },
    "interpreter": {
      "hash": "2a58c9d96f388a161021b4bdecdaac39da61e768cdb091263fbdbd9b82c7c06a"
    },
    "colab": {
      "name": "extract_surveys_nv_0209TP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a4YXlicSpvw"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_hZwGIuSpv0"
      },
      "source": [
        "Provide path to directory where the files are stored. This depends highly on how things are set up on your system. I downloaded the files from Qualtrics and put them in a dedicated directory. They are named e.g. baseline_1_text.csv, baseline_2_text.csv etc, same for the follow-up files. The way this program is set up is that it will ask you for input. When the prompt appears, just enter the name of the file you want to work on. Many ways to skin a cat though - this is just one way of dealing with the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTZSe3cOSpv2"
      },
      "source": [
        "home = 1\n",
        "if home:\n",
        "    infiledir = r\"C:\\Users\\Possible_online_studies\\NLP_expressive_writing\\analysis\"\n",
        "else:\n",
        "    infiledir = r\"P:\\EW_analysis\\analysis\"\n",
        "filename = input(\"Please enter input filename, including file extension.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKFRTXe0Spv3"
      },
      "source": [
        "These two files are needed to get the ADNM scores for the baseline questionnaires. More on this will follow below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8roBXL-dSpv3"
      },
      "source": [
        "screening_df = pd.read_csv(os.path.join(infiledir, 'screening.csv'),skiprows = [0,2]) # read in screening and randomisation files\n",
        "randomisation_df = pd.read_csv(os.path.join(infiledir, 'randomisation.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbMCj2smSpv4"
      },
      "source": [
        "Here, you enter the assessment number you are working on (so 1,2 3 or 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1B2IbMSpv4"
      },
      "source": [
        "# assessment number\n",
        "assessment_number = input(\"Please enter the assessment number (1, 2, 3 or 4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwEdxL9HSpv5"
      },
      "source": [
        "Here, you specify where you want the output to go and what you want it to be called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vHNAlcKSpv5"
      },
      "source": [
        "# Save output here\n",
        "if home:\n",
        "    output_dir = r\"C:\\Users\\Luzia T\\UCL\\WorkingFromHome\\Possible_online_studies\\NLP_expressive_writing\\analysis\\Processed_2\"\n",
        "else:\n",
        "    output_dir = r\"P:\\EW_analysis\\analysis\\Processed_2\"\n",
        "outfilename = input(\"Please enter desired output file name, including file extension.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3WoRezYSpv6"
      },
      "source": [
        "Now we read in the Qualtrics file. This is pretty basic, I'm not really using any of the filter options other than the skiprows argument. This is to skip rows 0 and 2, which are just confusing and don't hold any additional information that I want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j09_XmYVSpv7"
      },
      "source": [
        "test_df= pd.read_csv(os.path.join(infiledir, filename),skiprows = [0,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGDb_iqSpv7"
      },
      "source": [
        "One of the trickier things of dealing with this data set is that there are duplicate records for certain ids. There may be many reasons for this. For instance, a participant may have started an assessment, encountered issues, and stopped, then started again, resulting in multiple records for the same id. Some participants may not have been able to click through to the Gorilla task, resulting in 'complete' status in Qualtrics, but no Gorilla record. Although most of these people got a link to the assessment only, some participants just recompleted the entire thing, resulting in multiple records for the same person. Here's how we will proceed in removing duplicate ids:\n",
        "(1) Remove any rows with incomplete status\n",
        "(2) Remove rows for duplicate ids if they contain <70% of valid data\n",
        "(3) Check Qualtrics ID against LDI record. If one of them exists but the other does not, use the record with the existing MST record.\n",
        "(4) If all duplicates for a single ID contain data, use the one with the later completion date/time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uXXpEwbSpv8",
        "outputId": "a08ff9be-f364-4b27-988e-bdfc9af9b6eb"
      },
      "source": [
        "# Find incomplete records and duplicates\n",
        "test_df.rename(columns = {'Please enter the participant number you were sent.': 'id'},inplace = True)\n",
        "incomplete = test_df[test_df['Finished']==False]['id']\n",
        "print('Did not finish:', incomplete)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not finish: 11      NaN\n",
            "41     68.0\n",
            "87    112.0\n",
            "Name: id, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgQMEgoXSpv9"
      },
      "source": [
        "Drop rows with 'incomplete' status."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzUGaBjsSpv9"
      },
      "source": [
        "test_df.drop(labels = incomplete.index, axis = 0, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trstoA1iSpv-"
      },
      "source": [
        "Now check for duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXvq_R3GSpv-",
        "outputId": "5759518e-0af0-47d6-fe55-3645a63e87fe"
      },
      "source": [
        "duplicates = test_df[test_df.duplicated(subset = 'id')]\n",
        "print(duplicates['id'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67    107.0\n",
            "80    219.0\n",
            "Name: id, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQrU4HdISpv_"
      },
      "source": [
        "Now we check for rows with duplicate ids and >70% of invalid (nan or 0) data. We do this for each duplicated id in turn, since we don't know how many times someone attempted the questionnaire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVbEtOw0Spv_",
        "outputId": "e9cee53a-425b-4b71-93a8-d2419ee9c385"
      },
      "source": [
        "drop_labels = []\n",
        "for count, pnum in enumerate(duplicates.id):\n",
        "    dup_df = test_df[test_df.id==pnum]\n",
        "    prop_nil = dup_df.replace(0,np.nan).isna().sum(axis = 1)/dup_df.shape[1]\n",
        "    drop_ind = prop_nil[prop_nil>0.7]\n",
        "    drop_labels.append(drop_ind)\n",
        "\n",
        "if np.array(drop_labels).size==0:\n",
        "    print('No empty rows to drop.')\n",
        "else:\n",
        "    test_df = test_df.drop(labels = drop_ind.index, axis = 0)\n",
        "    print('dropped labels: ', np.array(drop_labels))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No empty rows to drop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkUUY0ivSpwA"
      },
      "source": [
        "We now check for any remaining duplicated records. We then use the info from the LDI file to check if, for a given ID, one record has an existing MST result while the other(s) do/does not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptZRJmlSpwA",
        "outputId": "59bd7399-1f9b-4459-cf82-5c3da05afabd"
      },
      "source": [
        "duplicates = test_df[test_df.duplicated(subset = 'id',keep = False)]\n",
        "print(duplicates['id'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64    107.0\n",
            "67    107.0\n",
            "79    219.0\n",
            "80    219.0\n",
            "Name: id, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGRmQB4RSpwA"
      },
      "source": [
        "Load the LDI file from appropriate directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-eD4xjcSpwA",
        "outputId": "1e5df2f8-044f-407e-b9b8-8237dec619fa"
      },
      "source": [
        "if home:\n",
        "    MST_dir = r\"C:\\Users\\Luzia T\\UCL\\WorkingFromHome\\Possible_online_studies\\NLP_expressive_writing\\analysis\\Processed_data\\MST\"\n",
        "else:\n",
        "    MST_dir = r\"P:\\EW_analysis\\analysis\\Processed_data\\MST\"\n",
        "ldi_name = input(\"Please enter the name of the file with the LDI results, including file extension. \")\n",
        "LDI_df = pd.read_csv(os.path.join(MST_dir, ldi_name))\n",
        "LDI_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        qualtrics_id  rec_part  ldi_part  targets  lures  rec_prob  ldi_prob  \\\n",
              "0  R_3E0TOIqjlwa684F        42         0      128    128  0.328125  0.000000   \n",
              "1  R_2ZPsf7B81JXlKoE        60         3      128    128  0.468750  0.023438   \n",
              "2  R_2qjSlzamK6c9Y66        54         9      128    128  0.421875  0.070312   \n",
              "3  R_3q7FKiW4r0tYTu4        56        19      128    128  0.437500  0.148438   \n",
              "4  R_O6vCXXxaVVrmeJP        61        23      128    128  0.476562  0.179688   \n",
              "\n",
              "             date_time  task_type  \n",
              "0  2020-10-28 16:29:00          1  \n",
              "1  2020-10-30 09:27:00          1  \n",
              "2  2020-11-02 10:22:00          1  \n",
              "3  2020-11-02 11:55:00          1  \n",
              "4  2020-11-02 12:47:00          1  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qualtrics_id</th>\n",
              "      <th>rec_part</th>\n",
              "      <th>ldi_part</th>\n",
              "      <th>targets</th>\n",
              "      <th>lures</th>\n",
              "      <th>rec_prob</th>\n",
              "      <th>ldi_prob</th>\n",
              "      <th>date_time</th>\n",
              "      <th>task_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R_3E0TOIqjlwa684F</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.328125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2020-10-28 16:29:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R_2ZPsf7B81JXlKoE</td>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.023438</td>\n",
              "      <td>2020-10-30 09:27:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R_2qjSlzamK6c9Y66</td>\n",
              "      <td>54</td>\n",
              "      <td>9</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.070312</td>\n",
              "      <td>2020-11-02 10:22:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R_3q7FKiW4r0tYTu4</td>\n",
              "      <td>56</td>\n",
              "      <td>19</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.148438</td>\n",
              "      <td>2020-11-02 11:55:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R_O6vCXXxaVVrmeJP</td>\n",
              "      <td>61</td>\n",
              "      <td>23</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.476562</td>\n",
              "      <td>0.179688</td>\n",
              "      <td>2020-11-02 12:47:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtRaiUklSpwB",
        "outputId": "cd260fad-c639-42ea-8686-26b337b88d51"
      },
      "source": [
        "# Get the qualtrics ids for the subjects with duplicate ids:\n",
        "qualtrics_ids = test_df.loc[duplicates.index,'Response ID']\n",
        "print(qualtrics_ids)\n",
        "ids_exist = qualtrics_ids[qualtrics_ids.isin(LDI_df.qualtrics_id)]\n",
        "print(ids_exist)\n",
        "# now drop the records with existing qualtrics ids from the duplicates\n",
        "duplicates.drop(labels = ids_exist.index, axis = 0, inplace = True)\n",
        "# Finally, use the remaining indices from duplicates to drop these records from the dataframe:\n",
        "test_df.drop(labels = duplicates.index, axis = 0, inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64    R_3r36lzHPejmI1tK\n",
            "67    R_2SDeL4CXliMT0Cu\n",
            "79    R_cIsj3jgNgnx6iM9\n",
            "80    R_28GQmOZwVVmGAES\n",
            "Name: Response ID, dtype: object\n",
            "67    R_2SDeL4CXliMT0Cu\n",
            "80    R_28GQmOZwVVmGAES\n",
            "Name: Response ID, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-soV_YTSpwB"
      },
      "source": [
        "Ok, now on to the last option. If we can't solve the duplicated id issue with any of the above, we will just use the record with the max date/time stamp as recorded by Qualtrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkqL5X9fSpwC",
        "outputId": "984743f0-3bcc-4cbe-b7c0-697d51cc0010"
      },
      "source": [
        "if test_df[test_df.duplicated(subset = 'id')].empty:\n",
        "    print('No more duplicates in ids.')\n",
        "else:\n",
        "    print('More duplicates left.')\n",
        "    duplicates = test_df[test_df.duplicated(subset = 'id', keep = False)]\n",
        "    test_df.loc[:,'Start Date'] = pd.to_datetime(test_df.loc[:,'Start Date']) # convert to date time format\n",
        "    for i, pnum in enumerate(duplicates.id.unique()):\n",
        "        id_df = test_df.loc[test_df.id == pnum,['Start Date','id']]\n",
        "        max_ind = id_df.where(id_df['Start Date']== id_df['Start Date'].max(),np.nan).dropna(how = 'all',axis = 0)\n",
        "        duplicates.drop(labels = max_ind.index,axis = 0, inplace = True)\n",
        "        print('Dropping ids: ',duplicates['id'])\n",
        "    test_df.drop(labels = duplicates.index, axis = 0, inplace =  True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No more duplicates in ids.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF1pdttiSpwC"
      },
      "source": [
        "Next, we'll drop rows where the id field is empty. We can't do anything with data that don't have a participant number associated with them, so we'll chuck them out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TjflVXcSpwC",
        "outputId": "9f71f982-a11b-420b-dfe1-db747d8c07d1"
      },
      "source": [
        "test_df = test_df.drop(labels = test_df[test_df.id.isna()].index, axis = 0)\n",
        "print(f'dropped {test_df[test_df.id.isna()].shape[0]} subjects due to missing id')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dropped 0 subjects due to missing id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK6k0H23SpwD"
      },
      "source": [
        "We're about to get the info that we are going to use for the rest of the analysis from the df. The below file just holds the names of the start and end of all the questionnaires we want to include for further processing.\n",
        "Bear in mind that again, this is one way of doing things. You could argue that, since we are dropping very few columns, we could just specify which cols we want to drop and then proceed to drop them. However, this way, we already have the column names for each of the questionnaires for the scoring bit later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCNUpHBCSpwD"
      },
      "source": [
        "col_key = pd.read_csv(os.path.join(infiledir, 'survey_cols.csv'),index_col = 0)#pd.read_csv(os.path.join(infiledir,qcode_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "478jgwyFSpwD"
      },
      "source": [
        "DASS_cols = test_df.loc[:,col_key.DASS['start']:col_key.DASS['end']].columns\n",
        "ERQ_cols = test_df.loc[:,col_key.ERQ['start']:col_key.ERQ['end']].columns\n",
        "RRS_cols = test_df.loc[:,col_key.RRS['start']:col_key.RRS['end']].columns\n",
        "SOC_cols = test_df.loc[:,col_key.SOC['start']:col_key.SOC['end']].columns\n",
        "GPAQ_cols = test_df.loc[:,col_key.GPAQ['start']:col_key.GPAQ['end']].columns\n",
        "PTGI_cols = test_df.loc[:,col_key.PTGI['start']:col_key.PTGI['end']].columns\n",
        "if 'follow' in filename:\n",
        "    Demographics_cols = test_df.loc[:,col_key.Demographics_follow['start']:col_key.Demographics_follow['end']].columns\n",
        "    ADNM_cols = test_df.loc[:,col_key.ADNM['start']:col_key.ADNM['end']].iloc[:,1:-1].columns\n",
        "    # There's a typo in the follow-up version of this, so need to specify separately.\n",
        "    PSQI_start = 'During the past month, how many hours of actual sleep did you get at night? (This may be different than the number of hours you spent in bed.) Please enter the average number of hours of sleep per night.'\n",
        "    PSQI_cols = test_df.loc[:,PSQI_start:col_key.PSQI['end']].columns\n",
        "    cols_to_keep = np.concatenate([Demographics_cols.values,ADNM_cols.values,DASS_cols.values,ERQ_cols.values,RRS_cols.values,SOC_cols.values,GPAQ_cols.values,PSQI_cols.values,PTGI_cols.values,['id','Response ID','Start Date']],axis = None)\n",
        "else:\n",
        "    Covid_cols = test_df.loc[:,col_key.Covid['start']:col_key.Covid['end']].columns\n",
        "    Demographics_cols = test_df.loc[:,col_key.Demographics['start']:col_key.Demographics['end']].columns\n",
        "    PSQI_cols = test_df.loc[:,col_key.PSQI['start']:col_key.PSQI['end']].columns\n",
        "    cols_to_keep = np.concatenate([Demographics_cols.values,Covid_cols.values,DASS_cols.values,ERQ_cols.values,RRS_cols.values,SOC_cols.values,GPAQ_cols.values,PSQI_cols.values,PTGI_cols.values,['id','Response ID','Start Date']],axis = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUr5WUfNSpwD",
        "outputId": "e99cf73b-8273-4cb4-fb01-2bcfe1c2305d"
      },
      "source": [
        "test_df = test_df.filter(items = cols_to_keep, axis = 1)\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86, 199)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R61VoKlNSpwE"
      },
      "source": [
        "There is also one additional thing we need to do before looking up the qualtrics ids. Some subjects had issues with the tasks. To allow them to complete just this bit without having to recomplete the entire thing, I made a separate qualtrics survey that just asked for their participant number and sent them straight through to Gorilla to complete the task. We'll now load the Qualtrics data from this and we'll replace the Qualtrics ID for those participants where this happened. Note that we are reading in the participant id column as float64. This is because we want it to be the same data type as the id column in test_df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqyUz1_oSpwE"
      },
      "source": [
        "MST_replaced_name = input('Please enter the replacement ID MST filename, including file extension: ')\n",
        "MST_replaced = pd.read_csv(os.path.join(MST_dir,MST_replaced_name),dtype = {'Please enter your participant ID': np.float64})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbjZ0_B9SpwE"
      },
      "source": [
        "Now we need to replace the Qualtrics IDs in our dataframe - if necessary. First of all, for easier manipulation, we'll set the index of the test_df dataframe to 'id'. Next, we will (i) check whether any ids need replacing and (ii) if yes, replace them. Here we are using a dict and then apply to accomplish this. You could also simply set the index to be id in the MST_replaced df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmsRm395SpwF"
      },
      "source": [
        "test_df.set_index('id',inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMjm2yGCSpwF",
        "outputId": "3ad38ec2-dbfb-43d0-f61d-bd93f3861d7d"
      },
      "source": [
        "for count,part in enumerate(MST_replaced['Please enter your participant ID']):\n",
        "    if part in test_df.index:\n",
        "        #print(part)\n",
        "        print('Qualtrics ID before replacement:', test_df['Response ID'][part])\n",
        "        test_df['Response ID'][part] = MST_replaced['Response ID'][count]\n",
        "        print('Qualtrics ID after replacement:', test_df['Response ID'][part])\n",
        "    else:\n",
        "        print('No need to replace id ', part)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qualtrics ID before replacement: R_3HnvbjkUffyX6ff\n",
            "Qualtrics ID after replacement: R_1jdK6kFzPV4b7fa\n",
            "Qualtrics ID before replacement: R_22m37yYKGWwJOC4\n",
            "Qualtrics ID after replacement: R_9WGNk5J81UbWsRb\n",
            "No need to replace id  39.0\n",
            "Qualtrics ID before replacement: R_SJe6YQWAZe6nrwt\n",
            "Qualtrics ID after replacement: R_20U7XQdLf4Z3W3c\n",
            "Qualtrics ID before replacement: R_BrzpINd29KjIhwt\n",
            "Qualtrics ID after replacement: R_2cvVJkOPcQBHHv0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJHATWGJSpwF",
        "outputId": "8d6a8bd0-626f-4e31-ead1-bb5f2e7cbd0f"
      },
      "source": [
        "test_df[test_df.index.duplicated(keep = False)].isna().sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfm9MYC3SpwG"
      },
      "source": [
        "We now need to score the questionnaires in the dataframe. To do this, we are using the column labels we loaded from a .csv file earlier to select the relevant columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19mhOlt0SpwG"
      },
      "source": [
        "test_df.loc[:,col_key.loc['start','DASS']:col_key.loc['end','DASS']] = test_df.loc[:,col_key.loc['start','DASS']:col_key.loc['end','DASS']].replace({'Did not apply to me at all':0,'Applied to me to some degree or some of the time':1,\n",
        "'Applied to me to a considerable degree or a good part of the time':2,'Applied to me very much or most of the time':3})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NUFse1BSpwG"
      },
      "source": [
        "We now get the column names for the DASS questionnaire and divide these into subsets for depression, anxiety and stress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7xnv7SgSpwH"
      },
      "source": [
        "DASS_items = test_df.loc[:,col_key.loc['start','DASS']:col_key.loc['end','DASS']].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xsC5x29SpwH"
      },
      "source": [
        "DASS_depression =DASS_items[[2,4,9,12,15,16,20]] \n",
        "DASS_stress = DASS_items[[0,5,7,10,11,13,17]]\n",
        "DASS_anxiety = DASS_items[[1,3,6,8,14,18,19]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAoZOUFTSpwH"
      },
      "source": [
        "Now we calculate the scores for each of the subscale. Since we used the DASS-21 here, we have to multiply each of the scores by two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX5ycUH4SpwH"
      },
      "source": [
        "test_df['dass_depression'] = test_df.filter(items = DASS_depression,axis = 1).sum(axis = 1)*2\n",
        "test_df['dass_stress'] = test_df.filter(items = DASS_stress,axis = 1).sum(axis = 1)*2\n",
        "test_df['dass_anxiety'] = test_df.filter(items = DASS_anxiety,axis = 1).sum(axis = 1)*2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuU97b8iSpwH"
      },
      "source": [
        "def categorize_score(df,col_name,new_name, cutoff_low, cutoff_hi,cat_names):\n",
        "    df[new_name] = df[col_name]\n",
        "    for i in range(len(cutoff_low)):\n",
        "        df[new_name][(df[col_name]>=cutoff_low[i])&(df[col_name]<=cutoff_hi[i])]=cat_names[i]\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ASc0Dy6SpwI"
      },
      "source": [
        "DASS_colow = [0,10,14,21,28]\n",
        "DASS_cohi = [9,13,20,27,999]\n",
        "catnames = ['Normal','Mild','Moderate','Severe','Extremely Severe']\n",
        "DASSa_colow = [0,8,10,15,20]\n",
        "DASSa_cohi = [7,9,14,19,999]\n",
        "DASSs_colow = [0,15,19,26,34]\n",
        "DASSs_cohi = [14,18,25,33,999]\n",
        "\n",
        "test_df = categorize_score(test_df,'dass_depression','dass_category_depression',DASS_colow,DASS_cohi,catnames)\n",
        "test_df = categorize_score(test_df,'dass_anxiety','dass_category_anxiety',DASSa_colow,DASSa_cohi,catnames)\n",
        "test_df = categorize_score(test_df,'dass_stress','dass_category_stress',DASSs_colow,DASSs_cohi,catnames)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BY4hqxmSpwI"
      },
      "source": [
        "We now go through similar steps for each of the questionnaires. The exact steps always depend on the survey in question and what we need from it.\n",
        "Below, we use a different method of dividing each questionnaire into its subscales. Here, I just specified the column names. The approach depends a bit on the questionnaire (eg how long are the questions, are there special characters etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHTv2fWHSpwI"
      },
      "source": [
        "# ERQ\n",
        "# This uses sliders, so we don't need to recode this.\n",
        "ERQ_reapp = [\"When I want to feel more positive emotion (such as joy or amusement), I change what I'm thinking about.\",\n",
        "\"When I want to feel less negative emotion (such as sadness or anger), I change what I'm thinking about.\",\n",
        "\"When I'm faced with a stressful situation, I make myself think about it in a way that helps me stay calm.\",\n",
        "\"When I want to feel more positive emotion, I change the way I'm thinking about the situation.\",\n",
        "\"I control my emotions by changing the way I think about the situation I'm in.\",\n",
        "\"When I want to feel less negative emotion, I change the way I'm thinking about the situation.\"]\n",
        "ERQ_sup = [\"I control my emotions by not expressing them.\",\n",
        "\"When I am feeling negative emotions, I make sure not to express them.\"\n",
        "\"When I am feeling positive emotions, I am careful not to express them.\"\n",
        "\"I keep my emotions to myself.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRPYMmNeSpwI"
      },
      "source": [
        "test_df['ERQ_total'] = test_df.filter(items = ERQ_reapp+ERQ_sup,axis = 1).sum(axis = 1)\n",
        "test_df['ERQ_reapp'] = test_df.filter(items = ERQ_reapp,axis = 1).sum(axis = 1)\n",
        "test_df['ERQ_sup'] = test_df.filter(items = ERQ_sup,axis = 1).sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSG88Iy0SpwJ"
      },
      "source": [
        "#PTGI\n",
        "test_df.loc[:,col_key.loc['start','PTGI']:col_key.loc['end','PTGI']] = test_df.loc[:,col_key.loc['start','PTGI']:col_key.loc['end','PTGI']].replace({'I did not experience this.':0,\n",
        "'I experienced this to a very small degree.':1,\n",
        "'I experienced this to a small degree.':2,\n",
        "'I experienced this to a moderate degree.':3,\n",
        "'I experienced this to a great degree.':4,\n",
        "'I experienced this to a very great degree.':5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s24LX9pSpwJ"
      },
      "source": [
        "#PTGI subscales\n",
        "PTGI_cols = test_df.loc[:,col_key.loc['start','PTGI']:col_key.loc['end','PTGI']].columns\n",
        "test_df['PTGI_Relating to Others'] = test_df.filter(items = PTGI_cols[[5,7,8,14,15,19,20]],axis = 1).sum(axis = 1)\n",
        "test_df['PTGI_New Possibilities'] = test_df.filter(items = PTGI_cols[[2,6,10,14,16]],axis = 1).sum(axis = 1)\n",
        "test_df['PTGI_Personal Strength'] = test_df.filter(items = PTGI_cols[[3,9,11,18]],axis = 1).sum(axis = 1)\n",
        "test_df['PTGI_Spiritual Enhancement'] = test_df.filter(items = PTGI_cols[[4,17]],axis = 1).sum(axis = 1)\n",
        "test_df['PTGI_Appreciation'] = test_df.filter(items = PTGI_cols[[0,1,12]],axis = 1).sum(axis = 1)\n",
        "test_df['PTGI_total'] = test_df.loc[:,col_key.loc['start','PTGI']:col_key.loc['end','PTGI']].sum(axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3RVNmn1SpwJ"
      },
      "source": [
        "test_df.loc[:,col_key.loc['start','RRS']:col_key.loc['end','RRS']] = test_df.loc[:,col_key.loc['start','RRS']:col_key.loc['end','RRS']].replace({'Almost never':1,'Sometimes':2,\n",
        "'Often':3,'Almost always':4})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVnZcWCSSpwJ"
      },
      "source": [
        "test_df['RRS_total'] = test_df.loc[:,col_key.loc['start','RRS']:col_key.loc['end','RRS']].sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyGKKAV6SpwK"
      },
      "source": [
        "For the Global Physical Activity Questionnaire, we are actually not going to use the WHO scoring system, since we are just involved in getting a measure of how much time they spend sitting/reclining or engaged in different intensities of physical activity. For each sub-category, we first convert hours to minutes, then add hours and minutes and multiply by days to get the total time per week.\n",
        "We use a slightly different approach here, making an interim df for the GPAQ data. This is just what seemed easiest to me in the moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxjmXDxNSpwK"
      },
      "source": [
        "# convert to minutes first - two ways of selecting data for variety\n",
        "test_df.loc[:,test_df.columns.str.contains('Hours')]= test_df.filter(like = 'Hours',axis = 1)*60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03_-H40SpwK"
      },
      "source": [
        "GPAQ_head = ['work_vigorous','days_work_vigorous','hours_work_vigorous','minutes_work_vigorous','work_moderate','days_work_moderate','hours_work_moderate','minutes_work_moderate',\n",
        "'transport','transport_days','transport_hours','transport_minutes',\n",
        "'sports_vigorous','days_sports_vigorous','hours_sports_vigorous','minutes_sports_vigorous','sports_moderate','days_sports_moderate','hours_sports_moderate','minutes_sports_moderate',\n",
        "'sitting_reclining_hours','sitting_reclining_minutes']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqaaUnFsSpwL"
      },
      "source": [
        "GPAQ_df = test_df.loc[:,col_key.loc['start','GPAQ']:col_key.loc['end','GPAQ']]\n",
        "GPAQ_df.columns = GPAQ_head "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jStYC4g_SpwL"
      },
      "source": [
        "test_df['GPAQ_vigorous_total'] = (GPAQ_df.days_work_vigorous*(GPAQ_df.hours_work_vigorous+GPAQ_df.minutes_work_vigorous))+(GPAQ_df.days_sports_vigorous*(GPAQ_df.hours_sports_vigorous+GPAQ_df.minutes_sports_vigorous))\n",
        "test_df['GPAQ_moderate_total'] = (GPAQ_df.days_work_moderate*(GPAQ_df.hours_work_moderate+GPAQ_df.minutes_work_moderate))+(GPAQ_df.days_sports_moderate*(GPAQ_df.hours_sports_moderate+GPAQ_df.minutes_sports_moderate))\n",
        "test_df['GPAQ_transport_total'] = GPAQ_df.transport_days*(GPAQ_df.transport_hours+GPAQ_df.transport_minutes)\n",
        "test_df['GPAQ_sitting_total'] = GPAQ_df.sitting_reclining_hours+GPAQ_df.sitting_reclining_minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb7QH-BDSpwL"
      },
      "source": [
        "#SOC - this is a rating scale so we don't need to do any conversion with a key here.\n",
        "test_df['SOC'] = test_df.loc[:,col_key.loc['start','SOC']:col_key.loc['end','SOC']].sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1Hk_VR4SpwL"
      },
      "source": [
        "For the PSQI, we only had two questions and only one of them needs scoring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wWBKzDWSpwL"
      },
      "source": [
        "#PSQI\n",
        "test_df.loc[:,col_key.loc['end','PSQI']] = test_df.loc[:,col_key.loc['end','PSQI']].replace({'Very good':0,'Fairly good': 1, 'Fairly bad':2, 'Very bad': 3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4smS4avtSpwL"
      },
      "source": [
        "Now we have to deal with the ADNM scores. This will be different for the baseline and follow up files, since the ADNM was part of the follow up assessments, but not of the baseline since it was done at the screening stage. Let's first deal with the follow-up files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7z8O-OrSpwM"
      },
      "source": [
        "ADNM_preoccupation = ['I have to think about the stressful situation repeatedly.',\n",
        "'I have to think about the stressful situation a lot and this is a great burden to me.',\n",
        "\"I constantly get memories of the stressful situation and can't do anything to stop them.\",\n",
        "'My thoughts often revolve around anything related to the stressful situation.']\n",
        "\n",
        "ADNM_failure = ['Since the stressful situation, I find it difficult to concentrate on certain things.',\n",
        "'Since the stressful situation, I do not like going to work or carrying out the necessary tasks in everyday life.',\n",
        "'Since the situation, I can no longer sleep properly.',\n",
        "'All in all, the situation causes serious impairment in my social or occupational life, my leisure time and other important areas of functioning.']\n",
        "\n",
        "ADNM_depression = ['Since the stressful situation, I feel low and sad.',\n",
        "'I rarely do those activities which I used to enjoy anymore.',\n",
        "'I have been feeling dispirited since the stressful situation and have little hope for the future.']\n",
        "\n",
        "ADNM_anxiety = ['If I think about the stressful situation, I find myself in a real state of anxiety.',\n",
        "'Since the stressful situation, I am scared of doing certain things or of getting into certain situations.']\n",
        "\n",
        "ADNM_impulse = ['I am nervous and restless since the stressful situation.',\n",
        "'Since the stressful situation, I lose my temper much quicker than I used to, even over small things.',\n",
        "'I have noticed that I am becoming more irritable due to the stressful situation.']\n",
        "\n",
        "ADNM_avoidance = ['I try to avoid talking about the stressful situation whenever possible.',\n",
        "'I avoid certain things that might remind me of the stressful situation.',\n",
        "'I try to dismiss the stressful situation from my memory.',\n",
        "'I try to suppress my feelings because they are a burden to me.']\n",
        "\n",
        "if 'follow' in filename:\n",
        "    ADNM_cols = test_df.loc[:,'Since the stressful situation, I feel low and sad.':'All in all, the situation causes serious impairment in my social or occupational life, my leisure time and other important areas of functioning.'].columns\n",
        "    ADNM_items = ADNM_cols[~ADNM_cols.str.contains('How long')]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzWpmOegSpwM"
      },
      "source": [
        "if 'follow' in filename:\n",
        "  test_df.loc[:,ADNM_cols] = test_df.loc[:,ADNM_cols].replace({'Never':1, 'Rarely':2,'Sometimes':3,'Often':4,'<1 month':1,'1-3 months':2, '3-6 months':3, 'more than 6 months':4})\n",
        "  test_df['ADNM_time_total'] = test_df.filter(like = 'How long have you had this reaction for?', axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_burden_total'] = test_df.filter(items = ADNM_items, axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_preoccupation'] = test_df.filter(items = ADNM_preoccupation,axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_failure'] = test_df.filter(items = ADNM_failure,axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_anxiety'] = test_df.filter(items = ADNM_anxiety,axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_depression'] = test_df.filter(items = ADNM_depression,axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_impulse'] = test_df.filter(items = ADNM_impulse,axis = 1).sum(axis = 1)\n",
        "  test_df['ADNM_avoidance'] = test_df.filter(items = ADNM_avoidance,axis = 1).sum(axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N3o28wISpwM"
      },
      "source": [
        "Now for the baseline files. As mentioned, the baseline ADNM was completed at screening, so this was part of a separate survey. At this stage, participants were identified based on their screening id, which was the last four digits of their phone number. We can link them to the participant id via the randomisation spreadsheet. The reason we need to do this is that we are not interested in having all the ADNM results from the screening survey, just the ones for the participants who were actually included.\n",
        "Below we combine the information from the screening and randomisation sheets to get the ADNM scores we need. Please see the comments below for further info on what each of the lines is supposed to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voYgzAOkSpwM"
      },
      "source": [
        "# extract numeric content from strings (used to extract participant numbers)- we'll need this function below.\n",
        "def find_number(text):\n",
        "    num = re.findall(r'[0-9]+',text)\n",
        "    return \" \".join(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1PUaaLASpwM"
      },
      "source": [
        "if 'base' in filename:\n",
        "    ADNM_cols = screening_df.loc[:,'Since the stressful situation, I feel low and sad.':'All in all, the situation causes serious impairment in my social or occupational life, my leisure time and other important areas of functioning.'].columns\n",
        "    ADNM_items = ADNM_cols[~ADNM_cols.str.contains('How long')]\n",
        "    randomisation_df.loc[:,['Screening Id','Participant number']] = randomisation_df.loc[:,['Screening Id','Participant number']].applymap(find_number).astype('float') # get numbers from strings and convert to float\n",
        "    screening_df.rename(columns = {'Please enter the last four digits of your phone number':'Screening Id'}, inplace = True) # rename screening id column in screening file for easier manipulation\n",
        "    screening_df = screening_df.replace({'Never':1, 'Rarely':2,'Sometimes':3,'Often':4,'<1 month':1,'1-3 months':2, '3-6 months':3, 'more than 6 months':4})\n",
        "    screening_df['ADNM_burden_total'] = screening_df.filter(items = ADNM_items, axis = 1).sum(axis = 1)\n",
        "    screening_df.drop(labels = screening_df[screening_df.ADNM_burden_total<40].index,axis = 0,inplace = True) # Some people needed several gos. Remove those duplicateswhere the total ADNM score was below the cutoff.\n",
        "    duplicated_ids = screening_df[screening_df['Screening Id'].duplicated(keep = False)] # get remaining duplicated ids\n",
        "    screening_df.drop(labels = duplicated_ids[duplicated_ids.ADNM_burden_total==duplicated_ids.ADNM_burden_total.min()].index,axis = 0,inplace = True) # I know there's only one more subject with duplicate values, so this will work\n",
        "    screening_df.set_index('Screening Id',inplace = True) #Set index of screening file to screening id for easier manipulation\n",
        "    missed_ids = randomisation_df[~randomisation_df['Screening Id'].isin(screening_df.index)]['Screening Id'] #check if any ids missing and print them\n",
        "    print('the following ids are missing:', missed_ids)\n",
        "    screening_df = screening_df.loc[randomisation_df['Screening Id'],:] #get data for relevant ids from screening file\n",
        "    screening_df['id'] = randomisation_df.set_index('Screening Id').loc[screening_df.index,'Participant number']   #add participant number to screening df\n",
        "    screening_df['ADNM_time_total'] = screening_df.filter(like = 'How long have you had this reaction for?', axis = 1).sum(axis = 1)\n",
        "    screening_df['ADNM_preoccupation'] = screening_df.filter(items = ADNM_preoccupation,axis = 1).sum(axis = 1)\n",
        "    screening_df['ADNM_failure'] = screening_df.filter(items = ADNM_failure,axis = 1).sum(axis = 1)\n",
        "    screening_df['ADNM_anxiety'] = screening_df.filter(items = ADNM_anxiety,axis = 1).sum(axis = 1)\n",
        "    screening_df['ADNM_depression'] = screening_df.filter(items = ADNM_depression,axis = 1).sum(axis = 1)\n",
        "    screening_df['ADNM_impulse'] = screening_df.filter(items = ADNM_impulse,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_time_total'] = screening_df.set_index('id').loc[test_df.index,'ADNM_time_total']\n",
        "    test_df['ADNM_burden_total']=screening_df.set_index('id').loc[test_df.index,'ADNM_burden_total']\n",
        "    test_df['ADNM_preoccupation'] = test_df.filter(items = ADNM_preoccupation,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_failure'] = test_df.filter(items = ADNM_failure,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_anxiety'] = test_df.filter(items = ADNM_anxiety,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_depression'] = test_df.filter(items = ADNM_depression,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_impulse'] = test_df.filter(items = ADNM_impulse,axis = 1).sum(axis = 1)\n",
        "    test_df['ADNM_avoidance'] = test_df.filter(items = ADNM_avoidance,axis = 1).sum(axis = 1)\n",
        "    test_df = pd.concat([test_df, screening_df.set_index('id').loc[test_df.index,ADNM_event_cols]],axis = 1)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMd0D27SpwN"
      },
      "source": [
        "That's it! We now have all the info we needed from this. We are now ready to save to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BBml234SpwN"
      },
      "source": [
        "test_df.to_csv(os.path.join(output_dir,outfilename))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
